{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1852026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"dataPoints.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to randomly split the data set into a training set, a validation set and a test set. Suggested\n",
    "percentages for this split are 70 %, 15% and 15%, respectively, **but feel free to experiment\n",
    "and change these numbers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()#change to matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train, test and validation set - way I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_rest = train_test_split(data, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test, data_validate = train_test_split(data_rest, test_size=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.transpose(data_train[:,0:2])\n",
    "Y_train = np.transpose(data_train[:,2:])\n",
    "X_validate = np.transpose(data_validate[:,0:2])\n",
    "Y_validate = np.transpose(data_validate[:,2:])\n",
    "X_test = np.transpose(data_test[:,0:2])\n",
    "Y_test = np.transpose(data_test[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0] # Size of the input vector X\n",
    "n_y = Y_train.shape[0] # Size of the input vector Y\n",
    "P = X_train.shape[1] # Size of the sample\n",
    "N = 5 # size of the hidden layer, # neurons, this is just for the moment to have some example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1. (Full minimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(N=5,n=2, n_y=1):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n -- size of the input layer\n",
    "    N -- size of the hidden layer\n",
    "    p -- size of the sample\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (N, n)\n",
    "                    b1 -- bias vector of shape (N, 1)\n",
    "                    V -- weight matrix of shape (n_y, N)\n",
    "    \"\"\"\n",
    "        \n",
    "    W1 = np.random.randn(N,n)# * 0.01\n",
    "\n",
    "    b1 = np.zeros(shape=(N, 1))\n",
    "    V = np.random.randn(n_y,N)# * 0.01\n",
    "    \n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"V\": V}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.22079611,  1.26060649],\n",
       "        [ 0.48578407, -0.27144872],\n",
       "        [ 0.22290262, -0.95780595],\n",
       "        [-0.28838301,  0.0411424 ],\n",
       "        [-0.72465247, -1.86281362]]), 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]), 'V': array([[-1.39038819, -2.81163925, -1.32584788, -0.35979724,  1.09425205]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(N,n)# * 0.01\n",
    "b1 = np.random.randn(N,1)# * 0.01\n",
    "V = np.random.randn(n_y,N)# * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3453473846874617"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(W1**2))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train\n",
    "W=W1\n",
    "V=V\n",
    "bias=b1\n",
    "true=data_train[:,2:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ro=10**-5#10**(-4) #10-5 unti, 10-3\n",
    "sigma=1\n",
    "P=P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(V.T)\n",
    "a[2]=W[:,0]\n",
    "a[3]=W[:,1]\n",
    "a[4]=bias\n",
    "omega=np.matrix(a)\n",
    "\n",
    "def second_norm(omega):\n",
    "    return np.linalg.norm(omega)**2   #,2)#**2\n",
    "\n",
    "def predict(V,W,bias):\n",
    "    '''\n",
    "    P - number of samples\n",
    "    predicted - f(x^p)\n",
    "    true - y^p\n",
    "    ro - the regularization parameter\n",
    "    bias\n",
    "    '''\n",
    "    #V=omega[:,0]\n",
    "    #W=omega[:,1:3]\n",
    "    #bias=omega[:,3]\n",
    "    \n",
    "\n",
    "    \n",
    "    def tanh(t,sigma=1):\n",
    "        return (np.exp(2*sigma*t)-1)/(np.exp(2*sigma*t)+1)\n",
    "    def activation_f(W,X,bias):\n",
    "        \n",
    "        return tanh(W.dot(X)-bias,sigma)\n",
    "#    print(V.shape)\n",
    "#    print(activation_f(W,X,bias).shape)    \n",
    "    predicted_values=V.dot(activation_f(W,X,bias))\n",
    "    return predicted_values#, W,bias\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reg_tr_error(omega):\n",
    "    '''\n",
    "    P - number of samples\n",
    "    predicted - f(x^p)\n",
    "    true - y^p\n",
    "    ro - the regularization parameter\n",
    "    omega - (v,w,b) - inp, inp, bias\n",
    "    '''  \n",
    "    V=omega.T[:N].reshape(1,N)\n",
    "    W=omega.T[N:N+2*N].reshape(N,2)\n",
    "    \n",
    "    bias=omega.T[N+2*N:].reshape(N,1)\n",
    "    predicted=predict(V,W,bias)\n",
    "    \n",
    "    \n",
    "    err=predicted-true.T\n",
    "    err_all=err.dot(err.T)\n",
    "    \n",
    "     #error=(np.sum((np.sum((predicted.T-true)**2, axis=1)))/(2*P))+ro*second_norm(omega)\n",
    "###    # (np.sum((predicted.T-true)**2))/(2*P)+ro*second_norm(omega)\n",
    "\n",
    "    \n",
    "    return ((err_all)/(2*P)+ro*second_norm(omega)).item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.531811308622794"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_tr_error(omega.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 0.0438354600771642\n",
       " hess_inv: array([[ 1.64612984e+01, -1.60842425e+00,  3.73043664e+01,\n",
       "         2.82764298e+01,  3.16773725e+00,  4.25598273e+00,\n",
       "        -7.81680203e+01,  4.18679134e+00, -1.86558777e+00,\n",
       "        -3.66287330e+01, -2.73281467e+00,  3.16935274e-01,\n",
       "        -3.56003146e-01, -4.70277048e+00, -2.06031358e+00,\n",
       "         2.50072733e+01, -4.94673661e+00,  5.12289860e+01,\n",
       "         9.42290518e-01, -6.28516057e+00],\n",
       "       [-1.60842425e+00,  5.43572665e+03, -2.09658370e+02,\n",
       "         5.44863800e+03, -8.88451598e-01,  2.08081038e+01,\n",
       "        -9.36408298e+01,  9.97000072e+01,  1.03847542e+02,\n",
       "         2.78975086e+02,  5.11227302e+01,  5.46135846e+01,\n",
       "         1.52212057e+01, -5.89186171e+01, -3.41079526e+01,\n",
       "         2.28404307e+01, -8.75314185e+01, -3.70997833e+02,\n",
       "        -4.33512273e+01,  1.89742875e+01],\n",
       "       [ 3.73043664e+01, -2.09658370e+02,  4.18007439e+02,\n",
       "         5.54312900e+02,  1.01370711e+02,  1.67290462e+01,\n",
       "        -1.22755115e+02,  3.52527086e+01, -1.91183503e+01,\n",
       "        -4.52239032e+02, -1.30175406e+01,  4.24565178e+00,\n",
       "         2.77131511e+00, -1.11328218e+02, -1.22189377e+01,\n",
       "         2.54583777e+01, -4.38080128e+01,  6.21113759e+02,\n",
       "         2.94017452e+01, -9.65773109e+01],\n",
       "       [ 2.82764298e+01,  5.44863800e+03,  5.54312900e+02,\n",
       "         1.54495762e+04,  5.41628253e+02,  7.35724397e+01,\n",
       "        -1.19167774e+02,  1.58393700e+02,  1.10381107e+02,\n",
       "        -5.24301925e+02,  2.68052200e+01,  3.68503132e+01,\n",
       "        -1.03049716e+02, -6.01719319e+02, -1.28598226e+01,\n",
       "        -4.08488856e+01, -1.93706891e+02,  7.34563898e+02,\n",
       "         5.03169791e+02, -2.99995834e+02],\n",
       "       [ 3.16773725e+00, -8.88451598e-01,  1.01370711e+02,\n",
       "         5.41628253e+02,  1.86155670e+02,  3.97271545e+00,\n",
       "        -3.22613733e+01, -3.68204376e+00, -5.74811422e-01,\n",
       "        -1.11001698e+02, -1.83948712e+01,  1.20932370e+01,\n",
       "        -8.44272471e+00, -1.70307890e+02,  1.48600871e+01,\n",
       "         3.60142799e+00,  2.34531478e+00,  1.57679238e+02,\n",
       "         2.74816404e+01, -9.19625222e+01],\n",
       "       [ 4.25598273e+00,  2.08081038e+01,  1.67290462e+01,\n",
       "         7.35724397e+01,  3.97271545e+00,  1.31929929e+01,\n",
       "        -2.15526588e+01,  2.25319581e+00, -1.16350797e+00,\n",
       "        -1.78228631e+01,  3.16524563e-01,  2.20003978e-01,\n",
       "         4.07175237e-01, -4.71150756e+00, -6.52448829e-01,\n",
       "         4.34892890e+00, -3.47302848e+00,  2.47076928e+01,\n",
       "         2.92628659e+00, -3.17121977e+00],\n",
       "       [-7.81680203e+01, -9.36408298e+01, -1.22755115e+02,\n",
       "        -1.19167774e+02, -3.22613733e+01, -2.15526588e+01,\n",
       "         7.97017044e+02, -1.45399352e+01,  2.91382896e+00,\n",
       "         1.15199836e+02,  6.71971569e+00, -3.63608767e+00,\n",
       "         2.92661612e+00,  3.05680076e+01,  8.06100061e+00,\n",
       "        -2.62698431e+02,  1.37121399e+01, -1.64354841e+02,\n",
       "         2.37527933e+00,  3.15546578e+01],\n",
       "       [ 4.18679134e+00,  9.97000072e+01,  3.52527086e+01,\n",
       "         1.58393700e+02, -3.68204376e+00,  2.25319581e+00,\n",
       "        -1.45399352e+01,  6.92408039e+00,  2.01174098e-01,\n",
       "        -3.39149298e+01,  1.38785188e+00,  5.72663007e-01,\n",
       "         1.20016398e+00, -1.18845297e+00, -3.67943748e+00,\n",
       "         3.34908273e+00, -7.60658394e+00,  4.66023074e+01,\n",
       "         1.05617003e+00, -3.98530367e+00],\n",
       "       [-1.86558777e+00,  1.03847542e+02, -1.91183503e+01,\n",
       "         1.10381107e+02, -5.74811422e-01, -1.16350797e+00,\n",
       "         2.91382896e+00,  2.01174098e-01,  3.47874515e+00,\n",
       "         1.99094066e+01,  3.12859578e+00,  8.14068876e-01,\n",
       "        -8.46423642e-01,  3.55158380e-01, -7.22173720e-01,\n",
       "         1.39785924e-01,  3.62509386e-01, -2.71548819e+01,\n",
       "        -5.43490148e-03,  2.71621351e+00],\n",
       "       [-3.66287330e+01,  2.78975086e+02, -4.52239032e+02,\n",
       "        -5.24301925e+02, -1.11001698e+02, -1.78228631e+01,\n",
       "         1.15199836e+02, -3.39149298e+01,  1.99094066e+01,\n",
       "         6.12520929e+02,  1.58816442e+01, -4.14207508e+00,\n",
       "        -2.02116133e+00,  1.14752692e+02,  8.58594203e+00,\n",
       "        -2.34992719e+01,  4.04351370e+01, -8.39447798e+02,\n",
       "        -2.87813455e+01,  9.78634611e+01],\n",
       "       [-2.73281467e+00,  5.11227302e+01, -1.30175406e+01,\n",
       "         2.68052200e+01, -1.83948712e+01,  3.16524563e-01,\n",
       "         6.71971569e+00,  1.38785188e+00,  3.12859578e+00,\n",
       "         1.58816442e+01,  2.07768341e+01, -1.11531473e+00,\n",
       "         1.10281013e-01,  1.54820229e+01, -2.07023889e+00,\n",
       "         2.95869690e-01, -6.99382847e-01, -2.12276037e+01,\n",
       "        -1.92639992e+00,  8.50733582e+00],\n",
       "       [ 3.16935274e-01,  5.46135846e+01,  4.24565178e+00,\n",
       "         3.68503132e+01,  1.20932370e+01,  2.20003978e-01,\n",
       "        -3.63608767e+00,  5.72663007e-01,  8.14068876e-01,\n",
       "        -4.14207508e+00, -1.11531473e+00,  1.88858783e+00,\n",
       "         3.87219638e-01, -1.12412720e+01,  4.90655904e-01,\n",
       "         1.09957632e+00, -9.61423184e-01,  5.99373386e+00,\n",
       "        -1.36896197e+00, -5.44717580e+00],\n",
       "       [-3.56003146e-01,  1.52212057e+01,  2.77131511e+00,\n",
       "        -1.03049716e+02, -8.44272471e+00,  4.07175237e-01,\n",
       "         2.92661612e+00,  1.20016398e+00, -8.46423643e-01,\n",
       "        -2.02116133e+00,  1.10281013e-01,  3.87219638e-01,\n",
       "         2.57622704e+00,  6.89624102e+00, -5.03222391e-01,\n",
       "        -1.31161850e+00, -1.22706824e+00,  2.39702275e+00,\n",
       "        -6.90374274e+00,  2.87670631e+00],\n",
       "       [-4.70277048e+00, -5.89186171e+01, -1.11328218e+02,\n",
       "        -6.01719319e+02, -1.70307890e+02, -4.71150756e+00,\n",
       "         3.05680076e+01, -1.18845297e+00,  3.55158380e-01,\n",
       "         1.14752692e+02,  1.54820229e+01, -1.12412720e+01,\n",
       "         6.89624102e+00,  1.91994075e+02, -1.12434493e+01,\n",
       "        -3.94417418e-01,  3.83810891e+00, -1.60225305e+02,\n",
       "        -2.73015442e+01,  1.05924491e+02],\n",
       "       [-2.06031358e+00, -3.41079526e+01, -1.22189377e+01,\n",
       "        -1.28598226e+01,  1.48600871e+01, -6.52448829e-01,\n",
       "         8.06100061e+00, -3.67943748e+00, -7.22173720e-01,\n",
       "         8.58594203e+00, -2.07023889e+00,  4.90655904e-01,\n",
       "        -5.03222391e-01, -1.12434493e+01,  1.18576985e+01,\n",
       "        -4.22171456e+00,  4.62822465e+00, -1.13765251e+01,\n",
       "         1.67487720e+00, -3.94012293e+00],\n",
       "       [ 2.50072733e+01,  2.28404307e+01,  2.54583777e+01,\n",
       "        -4.08488856e+01,  3.60142799e+00,  4.34892890e+00,\n",
       "        -2.62698431e+02,  3.34908273e+00,  1.39785924e-01,\n",
       "        -2.34992719e+01,  2.95869690e-01,  1.09957632e+00,\n",
       "        -1.31161850e+00, -3.94417418e-01, -4.22171456e+00,\n",
       "         1.01116466e+02, -2.93492168e+00,  3.47890073e+01,\n",
       "        -4.45421615e+00, -4.66971343e+00],\n",
       "       [-4.94673661e+00, -8.75314185e+01, -4.38080128e+01,\n",
       "        -1.93706891e+02,  2.34531478e+00, -3.47302848e+00,\n",
       "         1.37121399e+01, -7.60658394e+00,  3.62509386e-01,\n",
       "         4.04351370e+01, -6.99382847e-01, -9.61423184e-01,\n",
       "        -1.22706824e+00,  3.83810891e+00,  4.62822465e+00,\n",
       "        -2.93492168e+00,  1.14214611e+01, -5.42190957e+01,\n",
       "        -5.09392156e+00,  5.41266380e+00],\n",
       "       [ 5.12289860e+01, -3.70997833e+02,  6.21113759e+02,\n",
       "         7.34563898e+02,  1.57679238e+02,  2.47076928e+01,\n",
       "        -1.64354841e+02,  4.66023074e+01, -2.71548819e+01,\n",
       "        -8.39447798e+02, -2.12276037e+01,  5.99373386e+00,\n",
       "         2.39702275e+00, -1.60225305e+02, -1.13765251e+01,\n",
       "         3.47890073e+01, -5.42190957e+01,  1.15631124e+03,\n",
       "         3.90803097e+01, -1.35781434e+02],\n",
       "       [ 9.42290518e-01, -4.33512273e+01,  2.94017452e+01,\n",
       "         5.03169791e+02,  2.74816404e+01,  2.92628659e+00,\n",
       "         2.37527933e+00,  1.05617003e+00, -5.43490147e-03,\n",
       "        -2.87813455e+01, -1.92639992e+00, -1.36896197e+00,\n",
       "        -6.90374274e+00, -2.73015442e+01,  1.67487720e+00,\n",
       "        -4.45421615e+00, -5.09392156e+00,  3.90803097e+01,\n",
       "         3.17241925e+01, -1.48022748e+01],\n",
       "       [-6.28516057e+00,  1.89742875e+01, -9.65773109e+01,\n",
       "        -2.99995834e+02, -9.19625222e+01, -3.17121977e+00,\n",
       "         3.15546578e+01, -3.98530367e+00,  2.71621351e+00,\n",
       "         9.78634611e+01,  8.50733582e+00, -5.44717580e+00,\n",
       "         2.87670631e+00,  1.05924491e+02, -3.94012293e+00,\n",
       "        -4.66971343e+00,  5.41266380e+00, -1.35781434e+02,\n",
       "        -1.48022748e+01,  6.48304520e+01]])\n",
       "      jac: array([-8.78237188e-07,  3.03145498e-07, -3.55765224e-07, -3.13390046e-07,\n",
       "       -1.13155693e-07, -1.49011612e-07, -1.47148967e-07,  6.80284575e-06,\n",
       "       -5.34253195e-06, -8.54488462e-07,  2.51457095e-08,  6.14672899e-08,\n",
       "       -5.07663935e-06, -8.81496817e-07, -4.75905836e-07, -1.23865902e-07,\n",
       "        2.60956585e-06, -5.91855496e-07,  5.09107485e-06,  1.36531889e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 7260\n",
       "      nit: 308\n",
       "     njev: 330\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ -0.92091524, -12.16604279,   1.90554302, -14.76095587,\n",
       "         2.11069889,   0.09314848,  -4.8654563 ,   0.48071755,\n",
       "         0.37773609,   3.10771969,   0.18232333,  -0.05760685,\n",
       "        -0.10251201,   2.13744437,  -0.23277153,   1.72067989,\n",
       "        -1.01360429,  -4.31416523,   0.6276764 ,   1.15383233])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(reg_tr_error,omega.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "all below niente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dsad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9b92fe535f13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdsad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#def plotApproximation():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dsad' is not defined"
     ]
    }
   ],
   "source": [
    "dsad\n",
    "#def plotApproximation():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_test\n",
    "W=W1\n",
    "V=V\n",
    "bias=b1\n",
    "true=data_test[:,2:]\n",
    "P=X.shape[1]\n",
    "P\n",
    "#predicted=mjau()\n",
    "\n",
    "\n",
    "\n",
    "ro=10**-5#10**(-4) #10-5 unti, 10-3\n",
    "sigma=1\n",
    "\n",
    "def predict():\n",
    "    '''\n",
    "    P - number of samples\n",
    "    predicted - f(x^p)\n",
    "    true - y^p\n",
    "    ro - the regularization parameter\n",
    "    bias\n",
    "    '''\n",
    "    def tanh(t,sigma=1):\n",
    "        return (np.exp(2*sigma*t)-1)/(np.exp(2*sigma*t)+1)\n",
    "    def activation_f(W,X,bias):\n",
    "        return tanh(W.dot(X)-bias,sigma)\n",
    "        \n",
    "    return (V.dot(activation_f(W,X,bias)))\n",
    "\n",
    "a=pd.DataFrame(V.T)\n",
    "a[2]=W[:,0]\n",
    "a[3]=W[:,1]\n",
    "a[4]=bias\n",
    "omega=np.matrix(a)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reg_tr_error():\n",
    "    '''\n",
    "    P - number of samples\n",
    "    predicted - f(x^p)\n",
    "    true - y^p\n",
    "    ro - the regularization parameter\n",
    "    omega - (v,w,b) - inp, inp, bias\n",
    "    '''  \n",
    "    predicted=predict()\n",
    "    error=(np.sum((np.sum((predicted.T-true)**2, axis=1)))/(2*P))+ro*second_norm(omega)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tr_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_tr_error(inp):#since omega is what we want to predict--> AKA W,V,bias\n",
    "    '''\n",
    "  \n",
    "    '''  \n",
    "    omega=inp\n",
    "    predicted=predict()\n",
    "    err=(predicted.T-true)\n",
    "    error=((err.T.dot(err))/(2*P))+ro*second_norm(omega)\n",
    "    omega=omega.flatten()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tr_error(omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(reg_tr_error,omega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ E(\\omega,\\pi) = \\frac{1}{2P}\\sum_{p=1}^{P}(f(x^p)-y^p)^2+\\rho \\| \\omega\\|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:\n",
    "        \n",
    "    the number of neurons N of the hidden layer\n",
    "    the spread delta in the activation function g(t)\n",
    "    the regularization parameter rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try the training initial error ??\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1,3])\n",
    "\n",
    "a1 = 1\n",
    "a2 = 2\n",
    "\n",
    "'''\n",
    "hyperparameters:\n",
    "        -\n",
    "        -\n",
    "        -\n",
    "'''\n",
    "\n",
    "functionArgs = [a1,a2]\n",
    "\n",
    "def fun(X, functionArgs):  #X is a vector\n",
    "    a1 = functionArgs[0] #unwrapping the arguments\n",
    "    a2 = functionArgs[1]\n",
    "    x1 = X[0] #unwrapping the variable\n",
    "    x2 = X[1]\n",
    "    return a1*x1**2 + a2*x2**2\n",
    "\n",
    "def fun_grad(X):\n",
    "    x1 = X[0]\n",
    "    x2 = X[1]\n",
    "\n",
    "    dx = functionArgs[0]*2*x1\n",
    "    dy = functionArgs[1]*2*x2\n",
    "    return np.array([dx,dy])\n",
    "\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "res=minimize(fun, x0, args=functionArgs,method='bfgs')\n",
    "print(res)\n",
    "running_time=time.time()-start\n",
    "\n",
    "print(running_time,np.linalg.norm(fun_grad(res.x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train\n",
    "n,m=X.shape\n",
    "w=np.random.randn(N,n) * 0.01\n",
    "\n",
    "#pred\n",
    "#y=\n",
    "#ro=\n",
    "def gradient(X,w,pred,y,ro):\n",
    "    for iter in range(100):\n",
    "           pred = X.dot(w.T)\n",
    "           err = pred-y\n",
    "           reg=2*(ro*w)\n",
    "           reg[-1]=0\n",
    "           grad = (err.T.dot(X) / P )+reg\n",
    "           w = w - alpha * grad\n",
    "           mean_square_error = err.T.dot(err) / P\n",
    "           grad_norm = abs(grad).sum()\n",
    "           if grad_norm<0.1 or mean_square_error<10: break\n",
    "           print(iter, grad_norm, mean_square_error)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_p = np.zeros(shape=(1,p)) # MSE on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Forward Propagation to calculate y_hat\n",
    "# tanh is implemented in Python with sigma=1\n",
    "for i in range(0,p):\n",
    "    X1 = np.reshape(X_train[:,1],(-1,1))\n",
    "    Z1 = np.dot(W1,X1) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    y_hat = np.dot(V,A1)\n",
    "    MSE_p[0,i] = (Y_train[0,i]-y_hat[0,0])**2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Def error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE():\n",
    "    for i in range(0,p):\n",
    "        X1 = np.reshape(X_train[:,1],(-1,1))\n",
    "        Z1 = np.dot(W1,X1) + b1\n",
    "        A1 = np.tanh(Z1)\n",
    "        y_hat = np.dot(V,A1)\n",
    "    MSE_p[0,i] = (Y_train[0,i]-y_hat[0,0])**2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optimization we could maybe pack in one vector V.transpose, W, b then they have the same number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(MSE_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_array = np.linspace(-np.pi, np.pi, 12) \n",
    "out_array = np.tanh(in_array) \n",
    "plt.plot(in_array, out_array, color = 'red', marker = \"o\") \n",
    "plt.title(\"numpy.tanh()\") \n",
    "plt.xlabel(\"X\") \n",
    "plt.ylabel(\"Y\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
